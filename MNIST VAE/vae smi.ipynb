{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example: Variational Autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kenn50/miniconda3/envs/wsl-test/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import argparse\n",
        "import inspect\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from jax import jit, lax, random\n",
        "from jax.example_libraries import stax\n",
        "import jax.numpy as jnp\n",
        "from jax.random import PRNGKey\n",
        "import jax\n",
        "\n",
        "import numpyro\n",
        "from numpyro import optim\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.examples.datasets import MNIST, load_dataset\n",
        "from numpyro.infer import SVI, Trace_ELBO\n",
        "\n",
        "from types import SimpleNamespace\n",
        "\n",
        "from numpyro.optim import Adagrad\n",
        "\n",
        "from numpyro.contrib.einstein import RBFKernel\n",
        "from mixture_guide_impl_source import MixtureGuidePredictive\n",
        "from stein_impl_source import SteinVI\n",
        "\n",
        "import vae_example\n",
        "\n",
        "from functools import partial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temp dir in kernel\n",
        "RESULTS_DIR = os.path.abspath(\n",
        "    os.path.join(os.path.dirname(inspect.getfile(lambda: None)), \".results\")\n",
        ")\n",
        "RESULTS_DIR = \"./smi_results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def encoder(hidden_dim, z_dim):\n",
        "    return stax.serial(\n",
        "        stax.Dense(hidden_dim, W_init=stax.randn()),\n",
        "        stax.Softplus,\n",
        "        stax.FanOut(2),\n",
        "        stax.parallel(\n",
        "            stax.Dense(z_dim, W_init=stax.randn()),\n",
        "            stax.serial(stax.Dense(z_dim, W_init=stax.randn()), stax.Exp),\n",
        "        ),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def decoder(hidden_dim, out_dim):\n",
        "    return stax.serial(\n",
        "        stax.Dense(hidden_dim, W_init=stax.randn()),\n",
        "        stax.Softplus,\n",
        "        stax.Dense(out_dim, W_init=stax.randn()),\n",
        "        stax.Sigmoid,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model(batch, hidden_dim=400, z_dim=None):\n",
        "    batch = jnp.reshape(batch, (batch.shape[0], -1))\n",
        "    batch_dim, out_dim = jnp.shape(batch)\n",
        "    decode = numpyro.module(\"decoder\", decoder(hidden_dim, out_dim), (batch_dim, z_dim))\n",
        "    with numpyro.plate(\"batch\", batch_dim):\n",
        "        z = numpyro.sample(\"z\", dist.Normal(0, 1).expand([z_dim]).to_event(1))\n",
        "        img_loc = decode(z)\n",
        "        return numpyro.sample(\"obs\", dist.Bernoulli(img_loc).to_event(1), obs=batch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def guide(batch, hidden_dim=400, z_dim=100):\n",
        "    batch = jnp.reshape(batch, (batch.shape[0], -1))\n",
        "    batch_dim, out_dim = jnp.shape(batch)\n",
        "\n",
        "    encode = numpyro.module(\"encoder\", encoder(hidden_dim, z_dim), (batch_dim, out_dim))\n",
        "    z_loc, z_std = encode(batch)\n",
        "    with numpyro.plate(\"batch\", batch_dim):\n",
        "        d = dist.Normal(z_loc, z_std).to_event(1)\n",
        "        \n",
        "        z = numpyro.sample(\"z\", d)\n",
        "        return z\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def time_f(func, active = False):\n",
        "    def time_func(*args, **kwargs):\n",
        "        t = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        if(active):\n",
        "            print(f\"took {time.time() - t}s to run {func.__name__}\")\n",
        "        return result\n",
        "    return time_func\n",
        "\n",
        "\n",
        "def binarize(rng_key, batch):\n",
        "    return random.bernoulli(rng_key, batch).astype(batch.dtype)\n",
        "\n",
        "\n",
        "args = SimpleNamespace()\n",
        "args.num_epochs = 50\n",
        "args.learning_rate =5.0e-3\n",
        "args.batch_size = 128\n",
        "args.z_dim = 51\n",
        "args.hidden_dim = 400\n",
        "args.ada_step_size = 0.05\n",
        "\n",
        "args.num_stein_particles = 10\n",
        "args.num_elbo_particles = 10\n",
        "\n",
        "\n",
        "\n",
        "encoder_nn = encoder(args.hidden_dim, args.z_dim)\n",
        "decoder_nn = decoder(args.hidden_dim, 28 * 28)\n",
        "adam = optim.Adam(args.learning_rate)\n",
        "ada = Adagrad(args.ada_step_size)\n",
        "\n",
        "\n",
        "method = SteinVI(\n",
        "    model,\n",
        "    guide,\n",
        "    ada,\n",
        "    RBFKernel(), \n",
        "    hidden_dim=args.hidden_dim, \n",
        "    z_dim=args.z_dim, \n",
        "    num_stein_particles=args.num_stein_particles, \n",
        "    num_elbo_particles=args.num_elbo_particles,\n",
        "    loss_temperature=3\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "rng_key = PRNGKey(0)\n",
        "train_init, train_fetch = load_dataset(\n",
        "    MNIST, batch_size=args.batch_size, split=\"train\"\n",
        ")\n",
        "test_init, test_fetch = load_dataset(\n",
        "    MNIST, batch_size=args.batch_size, split=\"test\"\n",
        ")\n",
        "num_train, train_idx = train_init()\n",
        "rng_key, rng_key_binarize, rng_key_init = random.split(rng_key, 3)\n",
        "sample_batch = binarize(rng_key_binarize, train_fetch(0, train_idx)[0])\n",
        "state = method.init(rng_key_init, sample_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "@jit\n",
        "def epoch_train(state, rng_key, train_idx):\n",
        "    def body_fn(i, val):\n",
        "        loss_sum, state = val\n",
        "        rng_key_binarize = random.fold_in(rng_key, i)\n",
        "        batch = binarize(rng_key_binarize, train_fetch(i, train_idx)[0])\n",
        "        state, loss = method.update(state, batch)\n",
        "        loss_sum += loss\n",
        "        return loss_sum, state\n",
        "\n",
        "    return lax.fori_loop(0, num_train, body_fn, (0.0, state))\n",
        "\n",
        "@partial(jit, static_argnums=(4,))\n",
        "def eval_data(state, rng_key, data_idx, num_test, data_fetch):\n",
        "    def body_fun(i, loss_sum):\n",
        "        rng_key_binarize = random.fold_in(rng_key, i)\n",
        "        batch = binarize(rng_key_binarize, data_fetch(i, data_idx)[0])\n",
        "        # FIXME: does this lead to a requirement for an rng_key arg in svi_eval?\n",
        "        loss = method.evaluate(state, batch) / len(batch)\n",
        "        loss_sum += loss\n",
        "        return loss_sum\n",
        "\n",
        "    loss = lax.fori_loop(0, num_test, body_fun, 0.0)\n",
        "    loss = loss / num_test\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "def encode_image(img, rng_key):\n",
        "    rng_key_binarize, rng_key_particle, rng_key_z = jax.random.split(rng_key, 3)\n",
        "\n",
        "    params = method.get_params(state)\n",
        "    test_sample = binarize(rng_key_binarize, img)\n",
        "\n",
        "    particle = jax.random.randint(rng_key_particle, 1, 0, args.num_stein_particles)\n",
        "    encoder_params = jax.tree.map(lambda x: x[particle], params[\"encoder$params\"])\n",
        "\n",
        "    z_mean, z_var =  encoder_nn[1](\n",
        "        encoder_params, test_sample.reshape([1, -1])\n",
        "    )\n",
        "    z = dist.Normal(z_mean, z_var).sample(rng_key_z)\n",
        "    return z\n",
        "\n",
        "def decode_image(z):\n",
        "    params = method.get_params(state)\n",
        "    decoder_params = params[\"decoder$params\"]\n",
        "\n",
        "    return decoder_nn[1](decoder_params, z).reshape([28, 28])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def reconstruct_img(epoch, rng_key, test_idx):\n",
        "    img = test_fetch(0, test_idx)[0][0]\n",
        "    plt.imsave(\n",
        "        os.path.join(RESULTS_DIR, \"original_epoch={}.png\".format(epoch)),\n",
        "        img,\n",
        "        cmap=\"gray\",\n",
        "    )\n",
        "    img_loc = decode_image(encode_image(img, rng_key))\n",
        "    plt.imsave(\n",
        "        os.path.join(RESULTS_DIR, \"recons_epoch={}.png\".format(epoch)),\n",
        "        img_loc,\n",
        "        cmap=\"gray\",\n",
        "    )\n",
        "\n",
        "def sample_imgs(rng_key, num_samples):\n",
        "    params = method.get_params(state)\n",
        "    decoder_params = params[\"decoder$params\"]\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        rng_key, sub_key = random.split(rng_key)\n",
        "        z = dist.Normal(0, 1).expand((args.z_dim,)).sample(sub_key)\n",
        "        img_loc = decoder_nn[1](decoder_params, z).reshape([28, 28])\n",
        "        plt.imsave(\n",
        "            f\"samples/sample{i}.png\",\n",
        "            img_loc,\n",
        "            cmap=\"gray\",\n",
        "        )\n",
        "        \n",
        "@jit\n",
        "def mse_loss(targets: jnp.ndarray, preds: jnp.ndarray):\n",
        "    def single_mse(target: jnp.ndarray, pred:jnp.ndarray):\n",
        "        target = target.reshape(-1)\n",
        "        pred = pred.reshape(-1)\n",
        "        return jnp.mean((target - pred)**2)\n",
        "    return jnp.mean(jax.vmap(single_mse)(targets, preds))\n",
        "\n",
        "\n",
        "def epoch_conclude_mse(rng_key, test_idx):\n",
        "    imgs = test_fetch(0, test_idx)[0]\n",
        "    reconstructed = jax.vmap(lambda img, key: decode_image(encode_image(img, key)))(imgs, jax.random.split(rng_key, len(imgs)))\n",
        "    return mse_loss(imgs, reconstructed)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: loss = 519.6119995117188 (64.62 s.), mse_loss = 0.03036164864897728\n",
            "Epoch 1: loss = 680.0198364257812 (20.17 s.), mse_loss = 0.021225888282060623\n",
            "Epoch 2: loss = 1098.8138427734375 (22.58 s.), mse_loss = 0.018522748723626137\n",
            "Epoch 3: loss = 794.8582153320312 (20.26 s.), mse_loss = 0.015220444649457932\n",
            "Epoch 4: loss = 904.6341552734375 (19.81 s.), mse_loss = 0.014950506389141083\n",
            "Epoch 5: loss = 934.9126586914062 (20.01 s.), mse_loss = 0.012691255658864975\n",
            "Epoch 6: loss = 920.4520874023438 (22.65 s.), mse_loss = 0.01248837634921074\n",
            "Epoch 7: loss = 938.6097412109375 (20.25 s.), mse_loss = 0.012817542999982834\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m t_start = time.time()\n\u001b[32m      6\u001b[39m num_train, train_idx = train_init()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m _, state = \u001b[43mtime_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_key_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m rng_key, rng_key_test, rng_key_train, rng_key_reconstruct = random.split(rng_key, \u001b[32m4\u001b[39m)\n\u001b[32m     10\u001b[39m num_test, test_idx = test_init()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtime_f.<locals>.time_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtime_func\u001b[39m(*args, **kwargs):\n\u001b[32m      3\u001b[39m     t = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m(active):\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms to run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wsl-test/lib/python3.12/site-packages/jax/example_libraries/optimizers.py:120\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(data, xs)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# The implementation here basically works by flattening pytrees. There are two\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# levels of pytrees to think about: the pytree of params, which we can think of\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# as defining an \"outer pytree\", and a pytree produced by applying init_fun to\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# each leaf of the params pytree, which we can think of as the \"inner pytrees\".\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Since pytrees can be flattened, that structure is isomorphic to a list of\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# lists (with no further nesting).\u001b[39;00m\n\u001b[32m    115\u001b[39m OptimizerState = namedtuple(\u001b[33m\"\u001b[39m\u001b[33mOptimizerState\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m                             [\u001b[33m\"\u001b[39m\u001b[33mpacked_state\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtree_def\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msubtree_defs\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    117\u001b[39m jax.tree_util.register_pytree_node(\n\u001b[32m    118\u001b[39m     OptimizerState,\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m xs: ((xs.packed_state,), (xs.tree_def, xs.subtree_defs)),\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m data, xs: OptimizerState(xs[\u001b[32m0\u001b[39m], data[\u001b[32m0\u001b[39m], data[\u001b[32m1\u001b[39m]))\n\u001b[32m    123\u001b[39m Array = Any\n\u001b[32m    124\u001b[39m Params = Any  \u001b[38;5;66;03m# Parameters are arbitrary nests of `jnp.ndarrays`.\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for i in range(args.num_epochs):\n",
        "    rng_key, rng_key_train, rng_key_test, rng_key_reconstruct = random.split(\n",
        "        rng_key, 4\n",
        "    )\n",
        "    t_start = time.time()\n",
        "    num_train, train_idx = train_init()\n",
        "    \n",
        "    _, state = time_f(epoch_train)(state, rng_key_train, train_idx)\n",
        "    rng_key, rng_key_test, rng_key_train, rng_key_reconstruct = random.split(rng_key, 4)\n",
        "    num_test, test_idx = test_init()\n",
        "    test_loss = time_f(eval_data)(state, rng_key_test, test_idx, num_test, test_fetch)\n",
        "    train_loss = time_f(eval_data)(state, rng_key_train, train_idx, num_train, train_fetch)\n",
        "    \n",
        "    time_f(reconstruct_img)(i, rng_key_reconstruct, test_idx)\n",
        "\n",
        "    rng_key, rng_key_mse = jax.random.split(rng_key)\n",
        "    mse_loss_val = epoch_conclude_mse(rng_key, test_idx)\n",
        "    print(\n",
        "        \"Epoch {}: loss = {} ({:.2f} s.), mse_loss = {}\".format(\n",
        "            i, train_loss, time.time() - t_start, mse_loss_val\n",
        "        )\n",
        "    )\n",
        "rng_key, rng_key_sample = random.split(rng_key)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_imgs(rng_key,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "reconstruct_img(100, rng_key, test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: loss = 143.7112579345703 (14.26 s.), mse_loss = 0.03674609214067459\n",
            "Epoch 1: loss = 121.81253814697266 (0.46 s.), mse_loss = 0.02517949976027012\n",
            "Epoch 2: loss = 115.04705047607422 (0.12 s.), mse_loss = 0.02047920599579811\n",
            "Epoch 3: loss = 111.99622344970703 (0.12 s.), mse_loss = 0.019579891115427017\n",
            "Epoch 4: loss = 110.09611511230469 (0.12 s.), mse_loss = 0.018653705716133118\n",
            "Epoch 5: loss = 109.02849578857422 (0.12 s.), mse_loss = 0.01928989216685295\n",
            "Epoch 6: loss = 107.8291015625 (0.12 s.), mse_loss = 0.017941094934940338\n",
            "Epoch 7: loss = 107.57439422607422 (0.12 s.), mse_loss = 0.017174717038869858\n",
            "Epoch 8: loss = 107.30595397949219 (0.12 s.), mse_loss = 0.01743471622467041\n",
            "Epoch 9: loss = 106.43675994873047 (0.12 s.), mse_loss = 0.018033649772405624\n",
            "Epoch 10: loss = 106.08879089355469 (0.12 s.), mse_loss = 0.018783163279294968\n",
            "Epoch 11: loss = 105.81175994873047 (0.12 s.), mse_loss = 0.017368517816066742\n",
            "Epoch 12: loss = 104.96485900878906 (0.12 s.), mse_loss = 0.01674378477036953\n",
            "Epoch 13: loss = 105.13158416748047 (0.12 s.), mse_loss = 0.016703523695468903\n",
            "Epoch 14: loss = 104.62661743164062 (0.12 s.), mse_loss = 0.015447555109858513\n"
          ]
        }
      ],
      "source": [
        "vae_example.main_with_args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "TO_DELETE=RESULTS_DIR\n",
        "\n",
        "# List all files in the directory\n",
        "for filename in os.listdir(TO_DELETE):\n",
        "    file_path = os.path.join(TO_DELETE, filename)\n",
        "    \n",
        "    # Check if it is a file (not a subdirectory)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)  # Remove the file\n",
        "        print(f\"Deleted file: {filename}\")\n",
        "os.rmdir(TO_DELETE, )\n",
        "os.makedirs(TO_DELETE, exist_ok=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "wsl-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
